{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b1401ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80089e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weeknumber</th>\n",
       "      <th>maxtempf</th>\n",
       "      <th>mintempf</th>\n",
       "      <th>precipitationinch</th>\n",
       "      <th>watertempf</th>\n",
       "      <th>stlheadcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41.833333</td>\n",
       "      <td>32.185185</td>\n",
       "      <td>0.366481</td>\n",
       "      <td>40.860000</td>\n",
       "      <td>17.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>42.043956</td>\n",
       "      <td>32.934066</td>\n",
       "      <td>0.410659</td>\n",
       "      <td>40.365055</td>\n",
       "      <td>17.395604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41.988764</td>\n",
       "      <td>33.550562</td>\n",
       "      <td>0.320674</td>\n",
       "      <td>39.600449</td>\n",
       "      <td>16.258427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44.470588</td>\n",
       "      <td>35.082353</td>\n",
       "      <td>0.316706</td>\n",
       "      <td>38.816706</td>\n",
       "      <td>14.552941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>47.132530</td>\n",
       "      <td>37.060241</td>\n",
       "      <td>0.461205</td>\n",
       "      <td>39.098072</td>\n",
       "      <td>16.879518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>46.101266</td>\n",
       "      <td>34.860759</td>\n",
       "      <td>0.289114</td>\n",
       "      <td>39.026835</td>\n",
       "      <td>14.443038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>48.488889</td>\n",
       "      <td>35.755556</td>\n",
       "      <td>0.259444</td>\n",
       "      <td>39.184000</td>\n",
       "      <td>18.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>49.344086</td>\n",
       "      <td>35.967742</td>\n",
       "      <td>0.333226</td>\n",
       "      <td>39.563871</td>\n",
       "      <td>19.860215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>48.868132</td>\n",
       "      <td>35.516484</td>\n",
       "      <td>0.250440</td>\n",
       "      <td>40.062418</td>\n",
       "      <td>22.505495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>51.898990</td>\n",
       "      <td>36.101010</td>\n",
       "      <td>0.370808</td>\n",
       "      <td>40.765455</td>\n",
       "      <td>32.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>55.347107</td>\n",
       "      <td>38.363636</td>\n",
       "      <td>0.287769</td>\n",
       "      <td>42.103802</td>\n",
       "      <td>43.371901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>55.102041</td>\n",
       "      <td>38.683673</td>\n",
       "      <td>0.276735</td>\n",
       "      <td>43.631122</td>\n",
       "      <td>43.892857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>56.004926</td>\n",
       "      <td>39.655172</td>\n",
       "      <td>0.235961</td>\n",
       "      <td>44.890837</td>\n",
       "      <td>48.083744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>58.200957</td>\n",
       "      <td>40.502392</td>\n",
       "      <td>0.266938</td>\n",
       "      <td>46.224306</td>\n",
       "      <td>55.751196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>58.096774</td>\n",
       "      <td>41.594470</td>\n",
       "      <td>0.270876</td>\n",
       "      <td>47.557143</td>\n",
       "      <td>53.695853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>59.728571</td>\n",
       "      <td>42.371429</td>\n",
       "      <td>0.214619</td>\n",
       "      <td>49.166000</td>\n",
       "      <td>45.309524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>62.895238</td>\n",
       "      <td>43.504762</td>\n",
       "      <td>0.182667</td>\n",
       "      <td>50.600000</td>\n",
       "      <td>41.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>64.398104</td>\n",
       "      <td>43.995261</td>\n",
       "      <td>0.172844</td>\n",
       "      <td>52.320379</td>\n",
       "      <td>39.056872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>65.929907</td>\n",
       "      <td>45.817757</td>\n",
       "      <td>0.141589</td>\n",
       "      <td>53.813645</td>\n",
       "      <td>50.556075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>67.626168</td>\n",
       "      <td>47.747664</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>55.279720</td>\n",
       "      <td>58.705607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>67.531100</td>\n",
       "      <td>48.708134</td>\n",
       "      <td>0.159139</td>\n",
       "      <td>56.715981</td>\n",
       "      <td>67.468900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>69.746479</td>\n",
       "      <td>50.751174</td>\n",
       "      <td>0.109812</td>\n",
       "      <td>57.811831</td>\n",
       "      <td>81.784038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>70.660633</td>\n",
       "      <td>50.791855</td>\n",
       "      <td>0.133801</td>\n",
       "      <td>59.099367</td>\n",
       "      <td>117.886878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>69.976744</td>\n",
       "      <td>51.776744</td>\n",
       "      <td>0.138651</td>\n",
       "      <td>60.151163</td>\n",
       "      <td>169.688372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>72.032407</td>\n",
       "      <td>52.222222</td>\n",
       "      <td>0.095231</td>\n",
       "      <td>61.399167</td>\n",
       "      <td>285.314815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>75.658768</td>\n",
       "      <td>54.701422</td>\n",
       "      <td>0.099621</td>\n",
       "      <td>63.078578</td>\n",
       "      <td>485.028436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>77.959091</td>\n",
       "      <td>55.863636</td>\n",
       "      <td>0.022591</td>\n",
       "      <td>64.838545</td>\n",
       "      <td>777.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>78.888889</td>\n",
       "      <td>56.527778</td>\n",
       "      <td>0.027963</td>\n",
       "      <td>66.340833</td>\n",
       "      <td>1294.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>79.347222</td>\n",
       "      <td>57.648148</td>\n",
       "      <td>0.015370</td>\n",
       "      <td>67.790833</td>\n",
       "      <td>2077.287037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>81.100917</td>\n",
       "      <td>58.201835</td>\n",
       "      <td>0.014541</td>\n",
       "      <td>69.032936</td>\n",
       "      <td>2858.669725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>82.518868</td>\n",
       "      <td>58.367925</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>69.926509</td>\n",
       "      <td>3534.731132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>81.635945</td>\n",
       "      <td>58.824885</td>\n",
       "      <td>0.018664</td>\n",
       "      <td>70.738157</td>\n",
       "      <td>3780.672811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>81.348624</td>\n",
       "      <td>58.697248</td>\n",
       "      <td>0.018165</td>\n",
       "      <td>70.876697</td>\n",
       "      <td>4089.940367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>79.932127</td>\n",
       "      <td>57.574661</td>\n",
       "      <td>0.029186</td>\n",
       "      <td>70.641357</td>\n",
       "      <td>3346.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>80.123288</td>\n",
       "      <td>56.132420</td>\n",
       "      <td>0.051233</td>\n",
       "      <td>70.120548</td>\n",
       "      <td>3017.401826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>78.163636</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>0.046273</td>\n",
       "      <td>69.395818</td>\n",
       "      <td>3058.404545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>77.120930</td>\n",
       "      <td>54.097674</td>\n",
       "      <td>0.048326</td>\n",
       "      <td>68.482233</td>\n",
       "      <td>2937.334884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>73.277512</td>\n",
       "      <td>52.990431</td>\n",
       "      <td>0.118947</td>\n",
       "      <td>67.278278</td>\n",
       "      <td>2514.861244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>74.065217</td>\n",
       "      <td>52.347826</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>66.431848</td>\n",
       "      <td>1660.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>70.767296</td>\n",
       "      <td>50.886792</td>\n",
       "      <td>0.149937</td>\n",
       "      <td>65.491321</td>\n",
       "      <td>932.830189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>65.949686</td>\n",
       "      <td>48.559748</td>\n",
       "      <td>0.208553</td>\n",
       "      <td>63.682264</td>\n",
       "      <td>523.515723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>63.372671</td>\n",
       "      <td>46.962733</td>\n",
       "      <td>0.189130</td>\n",
       "      <td>61.779379</td>\n",
       "      <td>340.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>62.624204</td>\n",
       "      <td>46.101911</td>\n",
       "      <td>0.196815</td>\n",
       "      <td>59.801401</td>\n",
       "      <td>193.203822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>57.975309</td>\n",
       "      <td>42.895062</td>\n",
       "      <td>0.304630</td>\n",
       "      <td>57.602222</td>\n",
       "      <td>122.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>55.069182</td>\n",
       "      <td>42.584906</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>55.384151</td>\n",
       "      <td>72.597484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>53.266667</td>\n",
       "      <td>41.613333</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>53.543600</td>\n",
       "      <td>59.526667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>49.770115</td>\n",
       "      <td>38.816092</td>\n",
       "      <td>0.369195</td>\n",
       "      <td>51.462759</td>\n",
       "      <td>48.252874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>46.094595</td>\n",
       "      <td>36.081081</td>\n",
       "      <td>0.349054</td>\n",
       "      <td>48.859189</td>\n",
       "      <td>36.635135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>44.391892</td>\n",
       "      <td>35.013514</td>\n",
       "      <td>0.383378</td>\n",
       "      <td>46.764865</td>\n",
       "      <td>31.878378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>42.123288</td>\n",
       "      <td>32.767123</td>\n",
       "      <td>0.307534</td>\n",
       "      <td>44.639452</td>\n",
       "      <td>27.589041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>41.306667</td>\n",
       "      <td>32.906667</td>\n",
       "      <td>0.351467</td>\n",
       "      <td>43.152800</td>\n",
       "      <td>19.186667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>41.661538</td>\n",
       "      <td>33.923077</td>\n",
       "      <td>0.404462</td>\n",
       "      <td>42.107692</td>\n",
       "      <td>19.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>43.477273</td>\n",
       "      <td>35.022727</td>\n",
       "      <td>0.594318</td>\n",
       "      <td>41.294545</td>\n",
       "      <td>18.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    weeknumber   maxtempf   mintempf  precipitationinch  watertempf  \\\n",
       "0            1  41.833333  32.185185           0.366481   40.860000   \n",
       "1            2  42.043956  32.934066           0.410659   40.365055   \n",
       "2            3  41.988764  33.550562           0.320674   39.600449   \n",
       "3            4  44.470588  35.082353           0.316706   38.816706   \n",
       "4            5  47.132530  37.060241           0.461205   39.098072   \n",
       "5            6  46.101266  34.860759           0.289114   39.026835   \n",
       "6            7  48.488889  35.755556           0.259444   39.184000   \n",
       "7            8  49.344086  35.967742           0.333226   39.563871   \n",
       "8            9  48.868132  35.516484           0.250440   40.062418   \n",
       "9           10  51.898990  36.101010           0.370808   40.765455   \n",
       "10          11  55.347107  38.363636           0.287769   42.103802   \n",
       "11          12  55.102041  38.683673           0.276735   43.631122   \n",
       "12          13  56.004926  39.655172           0.235961   44.890837   \n",
       "13          14  58.200957  40.502392           0.266938   46.224306   \n",
       "14          15  58.096774  41.594470           0.270876   47.557143   \n",
       "15          16  59.728571  42.371429           0.214619   49.166000   \n",
       "16          17  62.895238  43.504762           0.182667   50.600000   \n",
       "17          18  64.398104  43.995261           0.172844   52.320379   \n",
       "18          19  65.929907  45.817757           0.141589   53.813645   \n",
       "19          20  67.626168  47.747664           0.130187   55.279720   \n",
       "20          21  67.531100  48.708134           0.159139   56.715981   \n",
       "21          22  69.746479  50.751174           0.109812   57.811831   \n",
       "22          23  70.660633  50.791855           0.133801   59.099367   \n",
       "23          24  69.976744  51.776744           0.138651   60.151163   \n",
       "24          25  72.032407  52.222222           0.095231   61.399167   \n",
       "25          26  75.658768  54.701422           0.099621   63.078578   \n",
       "26          27  77.959091  55.863636           0.022591   64.838545   \n",
       "27          28  78.888889  56.527778           0.027963   66.340833   \n",
       "28          29  79.347222  57.648148           0.015370   67.790833   \n",
       "29          30  81.100917  58.201835           0.014541   69.032936   \n",
       "30          31  82.518868  58.367925           0.013774   69.926509   \n",
       "31          32  81.635945  58.824885           0.018664   70.738157   \n",
       "32          33  81.348624  58.697248           0.018165   70.876697   \n",
       "33          34  79.932127  57.574661           0.029186   70.641357   \n",
       "34          35  80.123288  56.132420           0.051233   70.120548   \n",
       "35          36  78.163636  55.600000           0.046273   69.395818   \n",
       "36          37  77.120930  54.097674           0.048326   68.482233   \n",
       "37          38  73.277512  52.990431           0.118947   67.278278   \n",
       "38          39  74.065217  52.347826           0.106250   66.431848   \n",
       "39          40  70.767296  50.886792           0.149937   65.491321   \n",
       "40          41  65.949686  48.559748           0.208553   63.682264   \n",
       "41          42  63.372671  46.962733           0.189130   61.779379   \n",
       "42          43  62.624204  46.101911           0.196815   59.801401   \n",
       "43          44  57.975309  42.895062           0.304630   57.602222   \n",
       "44          45  55.069182  42.584906           0.513333   55.384151   \n",
       "45          46  53.266667  41.613333           0.338200   53.543600   \n",
       "46          47  49.770115  38.816092           0.369195   51.462759   \n",
       "47          48  46.094595  36.081081           0.349054   48.859189   \n",
       "48          49  44.391892  35.013514           0.383378   46.764865   \n",
       "49          50  42.123288  32.767123           0.307534   44.639452   \n",
       "50          51  41.306667  32.906667           0.351467   43.152800   \n",
       "51          52  41.661538  33.923077           0.404462   42.107692   \n",
       "52          53  43.477273  35.022727           0.594318   41.294545   \n",
       "\n",
       "    stlheadcount  \n",
       "0      17.185185  \n",
       "1      17.395604  \n",
       "2      16.258427  \n",
       "3      14.552941  \n",
       "4      16.879518  \n",
       "5      14.443038  \n",
       "6      18.411111  \n",
       "7      19.860215  \n",
       "8      22.505495  \n",
       "9      32.484848  \n",
       "10     43.371901  \n",
       "11     43.892857  \n",
       "12     48.083744  \n",
       "13     55.751196  \n",
       "14     53.695853  \n",
       "15     45.309524  \n",
       "16     41.457143  \n",
       "17     39.056872  \n",
       "18     50.556075  \n",
       "19     58.705607  \n",
       "20     67.468900  \n",
       "21     81.784038  \n",
       "22    117.886878  \n",
       "23    169.688372  \n",
       "24    285.314815  \n",
       "25    485.028436  \n",
       "26    777.000000  \n",
       "27   1294.625000  \n",
       "28   2077.287037  \n",
       "29   2858.669725  \n",
       "30   3534.731132  \n",
       "31   3780.672811  \n",
       "32   4089.940367  \n",
       "33   3346.615385  \n",
       "34   3017.401826  \n",
       "35   3058.404545  \n",
       "36   2937.334884  \n",
       "37   2514.861244  \n",
       "38   1660.010870  \n",
       "39    932.830189  \n",
       "40    523.515723  \n",
       "41    340.260870  \n",
       "42    193.203822  \n",
       "43    122.481481  \n",
       "44     72.597484  \n",
       "45     59.526667  \n",
       "46     48.252874  \n",
       "47     36.635135  \n",
       "48     31.878378  \n",
       "49     27.589041  \n",
       "50     19.186667  \n",
       "51     19.615385  \n",
       "52     18.500000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into dataframe\n",
    "file_path = Path('../Resources/refactored_data/combineddata.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Pull desired columns\n",
    "df_stlhead_week_month = df[['weeknumber','monthvalue','maxtempf','mintempf','precipitationinch','watertempf','stlheadcount']]\n",
    "\n",
    "# Drop NaN values\n",
    "df = df_stlhead_week_month.dropna(axis=0)\n",
    "\n",
    "df = df.astype({'stlheadcount': 'int64'})\n",
    "\n",
    "# Make a df grouped by average count on monthvalue\n",
    "week_df = df.groupby(['weeknumber']).mean().reset_index()\n",
    "week_df = week_df.drop(columns = ['monthvalue'])\n",
    "week_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07da0b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3268.23793913    88.97420261 -2432.84865854  3463.16843855\n",
      "  3543.65809232  -744.07804323  3273.19747662  1532.85340095\n",
      " -1750.63485258   -89.45591142  -118.85032611  -620.54480332\n",
      "  -950.55130001  1660.80691277]\n",
      "Coefficients: \n",
      " [ 8.81354449e+01  2.18739432e+03 -5.43828354e+03 -1.49068602e+04\n",
      "  5.28161335e+02  1.15392154e+00  2.59168916e+01 -6.87865098e+01\n",
      "  4.01717934e+02  2.12786640e+01 -4.94672177e+01  1.77633249e+02\n",
      " -2.16103906e+03 -7.43015889e+01 -2.13592580e+02  6.04914307e+03\n",
      "  2.48575612e+02 -2.57300570e+03 -2.40439294e+03 -6.20210113e+01]\n",
      "Mean squared error: 1075326.52\n",
      "Coefficient of determination: 0.58\n",
      "Train:  0.9676781220006541\n",
      "Test:  0.5800296809424293\n"
     ]
    }
   ],
   "source": [
    "# Based Poly Regression\n",
    "\n",
    "target = ['stlheadcount']\n",
    "\n",
    "# Creating features\n",
    "X = week_df.drop('stlheadcount', axis=1)\n",
    "\n",
    "# Creating target\n",
    "y = week_df['stlheadcount']\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_features = poly.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, random_state=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "print(predict)\n",
    "print(\"Coefficients: \\n\", model.coef_)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predict))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, predict))\n",
    "\n",
    "print(\"Train: \", model.score(X_train, y_train))\n",
    "print(\"Test: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea774a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad09966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c42897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3268.23793913    88.97420261 -2432.84865854  3463.16843855\n",
      "  3543.65809233  -744.07804323  3273.19747662  1532.85340095\n",
      " -1750.63485259   -89.45591142  -118.85032611  -620.54480332\n",
      "  -950.55130001  1660.80691276]\n",
      "Coefficients: \n",
      " [ -1600.73998154   3906.18623722  -6824.48873352    472.17263581\n",
      "   5028.74499673    270.01764053   5348.10299034  -9167.23544501\n",
      "    876.49193568   3599.99079462  -9001.92370796  20876.62855087\n",
      "  -4158.05580272 -11085.5214776  -16212.14678113   7516.91803026\n",
      "  23951.61513117    -52.34537311  -3792.91687813  -7586.42298843]\n",
      "Mean squared error: 1075326.52\n",
      "Coefficient of determination: 0.58\n",
      "Train:  0.9676781220006563\n",
      "Test:  0.5800296809417667\n"
     ]
    }
   ],
   "source": [
    "# Standard Scaler\n",
    "\n",
    "target = ['stlheadcount']\n",
    "\n",
    "# Creating features\n",
    "X = week_df.drop('stlheadcount', axis=1)\n",
    "\n",
    "ss_X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Creating target\n",
    "y = week_df['stlheadcount']\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_features = poly.fit_transform(ss_X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, random_state=1)\n",
    "\n",
    "# ss_X_train = StandardScaler().fit_transform(X)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "print(predict)\n",
    "print(\"Coefficients: \\n\", model.coef_)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predict))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, predict))\n",
    "\n",
    "print(\"Train: \", model.score(X_train, y_train))\n",
    "print(\"Test: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2ebfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3268.23793913    88.97420261 -2432.84865854  3463.16843855\n",
      "  3543.65809233  -744.07804323  3273.19747662  1532.85340095\n",
      " -1750.63485259   -89.45591142  -118.85032611  -620.54480332\n",
      "  -950.55130001  1660.80691276]\n",
      "Coefficients: \n",
      " [ -11513.95078964   38323.65043538  -58246.67292008   -1439.26588938\n",
      "   20285.03973867    3120.20384614   55540.79184536  -95287.50183691\n",
      "   12127.18915996   35474.07673847  -84017.37497715  195020.10902806\n",
      "  -51703.98487192  -98171.92658487 -151581.01412279   93553.22585206\n",
      "  212300.60957071    -867.18533337  -44751.17403442  -63747.86518622]\n",
      "Mean squared error: 1075326.52\n",
      "Coefficient of determination: 0.58\n",
      "Train:  0.9676781220006583\n",
      "Test:  0.5800296809417469\n"
     ]
    }
   ],
   "source": [
    "# Min Max Scaler\n",
    "\n",
    "target = ['stlheadcount']\n",
    "\n",
    "# Creating features\n",
    "X = week_df.drop('stlheadcount', axis=1)\n",
    "\n",
    "mm_X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "# Creating target\n",
    "y = week_df['stlheadcount']\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_features = poly.fit_transform(mm_X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, random_state=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "print(predict)\n",
    "print(\"Coefficients: \\n\", model.coef_)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predict))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, predict))\n",
    "\n",
    "print(\"Train: \", model.score(X_train, y_train))\n",
    "print(\"Test: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93959586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df149869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3268.23793913    88.97420261 -2432.84865854  3463.16843855\n",
      "  3543.65809233  -744.07804323  3273.19747662  1532.85340095\n",
      " -1750.63485258   -89.45591142  -118.85032611  -620.54480332\n",
      "  -950.55130001  1660.80691276]\n",
      "Coefficients: \n",
      " [ 4.67117858e+03  1.80501303e+05 -3.19906403e+05 -8.85941803e+03\n",
      "  3.74343311e+04  3.24136561e+03  1.13347525e+05 -2.14457001e+05\n",
      "  1.26536584e+04  7.99325555e+04 -3.36840270e+05  8.62260727e+05\n",
      " -1.05982679e+05 -4.34565089e+05 -7.39108730e+05  2.11482268e+05\n",
      "  1.03638967e+06 -9.08821898e+02 -1.01280989e+05 -3.11562936e+05]\n",
      "Mean squared error: 1075326.52\n",
      "Coefficient of determination: 0.58\n",
      "Train:  0.967678122000658\n",
      "Test:  0.5800296809418122\n"
     ]
    }
   ],
   "source": [
    "# Max ABS Scaler\n",
    "\n",
    "target = ['stlheadcount']\n",
    "\n",
    "# Creating features\n",
    "X = week_df.drop('stlheadcount', axis=1)\n",
    "\n",
    "mabs_X = MaxAbsScaler().fit_transform(X)\n",
    "\n",
    "# Creating target\n",
    "y = week_df['stlheadcount']\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_features = poly.fit_transform(mabs_X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, random_state=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "print(predict)\n",
    "print(\"Coefficients: \\n\", model.coef_)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predict))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, predict))\n",
    "\n",
    "print(\"Train: \", model.score(X_train, y_train))\n",
    "print(\"Test: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445899f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3268.23793913    88.97420261 -2432.84865854  3463.16843855\n",
      "  3543.65809233  -744.07804323  3273.19747662  1532.85340095\n",
      " -1750.63485259   -89.45591142  -118.85032611  -620.54480332\n",
      "  -950.55130001  1660.80691276]\n",
      "Coefficients: \n",
      " [   254.62598469   -726.89042456  -1913.58375495  -1434.42553211\n",
      "   1891.69962348    780.05096154  16447.99667906 -29092.24798831\n",
      "   2239.58876709  11997.53595718 -29473.45065435  70531.26423987\n",
      " -11310.79362607 -39330.47638143 -56518.09032871  21099.30874261\n",
      "  87686.66065619   -118.30093389 -11180.30142868 -29166.71748106]\n",
      "Mean squared error: 1075326.52\n",
      "Coefficient of determination: 0.58\n",
      "Train:  0.9676781220006563\n",
      "Test:  0.5800296809417818\n"
     ]
    }
   ],
   "source": [
    "# Robust Scaler\n",
    "\n",
    "target = ['stlheadcount']\n",
    "\n",
    "# Creating features\n",
    "X = week_df.drop('stlheadcount', axis=1)\n",
    "\n",
    "rs_X = RobustScaler(quantile_range=(25, 75)).fit_transform(X)\n",
    "\n",
    "# Creating target\n",
    "y = week_df['stlheadcount']\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_features = poly.fit_transform(rs_X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, random_state=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "print(predict)\n",
    "print(\"Coefficients: \\n\", model.coef_)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predict))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, predict))\n",
    "\n",
    "print(\"Train: \", model.score(X_train, y_train))\n",
    "print(\"Test: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c098fae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3019.50941503  1064.04521953 -3985.65636551  3196.58285136\n",
      "  3242.12180319 -1194.76454775  2945.19462843  1477.24108739\n",
      " -2654.43543978     7.985921     -16.34223933  -719.23879367\n",
      " -1010.18091832  2688.2036763 ]\n",
      "Coefficients: \n",
      " [ -1980.27326621   4263.60825203  -8140.47094079    249.21028979\n",
      "   6024.04835922     45.71476916   7867.37865647 -10686.39720467\n",
      "   2328.5615682    4062.34363085 -14885.04106171  39069.09630654\n",
      "  -4429.16164284 -19962.99818488 -24012.94363391  11545.17895489\n",
      "  26051.17609962    150.53321302  -8390.46979108  -6437.70294021]\n",
      "Mean squared error: 2608697.37\n",
      "Coefficient of determination: -0.02\n",
      "Train:  0.95763504529997\n",
      "Test:  -0.018830510406323997\n"
     ]
    }
   ],
   "source": [
    "# Power Transformer\n",
    "\n",
    "target = ['stlheadcount']\n",
    "\n",
    "# Creating features\n",
    "X = week_df.drop('stlheadcount', axis=1)\n",
    "\n",
    "pt_X = PowerTransformer(method=\"yeo-johnson\").fit_transform(X)\n",
    "\n",
    "# Creating target\n",
    "y = week_df['stlheadcount']\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_features = poly.fit_transform(pt_X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, random_state=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "print(predict)\n",
    "print(\"Coefficients: \\n\", model.coef_)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predict))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, predict))\n",
    "\n",
    "print(\"Train: \", model.score(X_train, y_train))\n",
    "print(\"Test: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155893b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3190.77354117  1284.38785695 -3389.81938467  3243.50394169\n",
      "  3252.35457484 -1105.55634226  3009.52764294  1391.2773596\n",
      " -2357.90821989    43.54597605    60.97510047  -373.10659025\n",
      "  -798.9911783   2359.38672069]\n",
      "Coefficients: \n",
      " [-1.74914306e+03  3.37341723e+03 -7.22451452e+03  3.25056197e+01\n",
      "  5.56134591e+03 -4.77576547e+01  7.04850739e+03 -8.86755879e+03\n",
      "  2.26867058e+03  2.94224346e+03 -1.08177165e+04  3.27017002e+04\n",
      " -1.71365199e+03 -1.77991208e+04 -2.03264708e+04  9.44055719e+03\n",
      "  2.07107706e+04  6.12960649e+02 -8.14557541e+03 -4.24626150e+03]\n",
      "Mean squared error: 2006831.95\n",
      "Coefficient of determination: 0.22\n",
      "Train:  0.9615480692907802\n",
      "Test:  0.2162288974007015\n"
     ]
    }
   ],
   "source": [
    "# Power Transformer\n",
    "\n",
    "target = ['stlheadcount']\n",
    "\n",
    "# Creating features\n",
    "X = week_df.drop('stlheadcount', axis=1)\n",
    "\n",
    "pt_X = PowerTransformer(method=\"box-cox\").fit_transform(X)\n",
    "\n",
    "# Creating target\n",
    "y = week_df['stlheadcount']\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_features = poly.fit_transform(pt_X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, random_state=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "print(predict)\n",
    "print(\"Coefficients: \\n\", model.coef_)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predict))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, predict))\n",
    "\n",
    "print(\"Train: \", model.score(X_train, y_train))\n",
    "print(\"Test: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc810c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3696.79709001  3394.13697087   622.12991066  4155.80304387\n",
      "  3965.9207677    599.68803576  4106.54285182  1697.0934735\n",
      "   109.65368228  -252.88994953  -282.35924704  1496.83121821\n",
      "   395.51059999 -2900.3730062 ]\n",
      "Coefficients: \n",
      " [-48995.96521916 -73566.89779778  17653.7458588  -17547.04440713\n",
      "  48783.44282289   6991.63624591 -31603.95144512   4951.12234414\n",
      "  34532.36925786  64584.4015915    -307.08648881  35729.75430475\n",
      "  76564.23318185  70135.12448169 -49897.50553881 -15319.27964165\n",
      "  30843.94852406   3133.45329115 -66424.48532319 -86975.51912285]\n",
      "Mean squared error: 1784761.06\n",
      "Coefficient of determination: 0.30\n",
      "Train:  0.9612251180512505\n",
      "Test:  0.30295900115734054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mthal\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2593: UserWarning: n_quantiles (1000) is greater than the total number of samples (53). n_quantiles is set to n_samples.\n",
      "  \"n_samples.\" % (self.n_quantiles, n_samples)\n"
     ]
    }
   ],
   "source": [
    "# QuantileTransformer\n",
    "\n",
    "target = ['stlheadcount']\n",
    "\n",
    "# Creating features\n",
    "X = week_df.drop('stlheadcount', axis=1)\n",
    "\n",
    "qt_X =QuantileTransformer(output_distribution=\"uniform\").fit_transform(X)\n",
    "\n",
    "# Creating target\n",
    "y = week_df['stlheadcount']\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_features = poly.fit_transform(qt_X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, random_state=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "print(predict)\n",
    "print(\"Coefficients: \\n\", model.coef_)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predict))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, predict))\n",
    "\n",
    "print(\"Train: \", model.score(X_train, y_train))\n",
    "print(\"Test: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c683d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.50868575e+04 -2.91821192e+03  6.84046950e+03 -7.30449565e+04\n",
      "  5.71602879e+04 -1.98915256e+02  4.54810231e+03  1.28961159e+03\n",
      "  3.27406482e+01  5.08906170e+01  7.41836911e+02 -1.06420441e+05\n",
      "  5.80121455e+01 -6.50777010e+02]\n",
      "Coefficients: \n",
      " [ -1931.6918598    1569.04543278   -291.06412835    633.76016512\n",
      "   2867.38101752    989.68326301  -5119.41020231  -2416.62141033\n",
      "   -396.14009834   8241.62423266   2038.1712911  -18609.72607769\n",
      "  -5819.30768275   9877.49070579   5636.93023615    677.20551023\n",
      "   7658.97329092  -1170.63572789   1997.39922451  -8368.63896217]\n",
      "Mean squared error: 1916924913.57\n",
      "Coefficient of determination: -747.66\n",
      "Train:  0.9636723286037386\n",
      "Test:  -747.6577816330079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mthal\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2593: UserWarning: n_quantiles (1000) is greater than the total number of samples (53). n_quantiles is set to n_samples.\n",
      "  \"n_samples.\" % (self.n_quantiles, n_samples)\n"
     ]
    }
   ],
   "source": [
    "# QuantileTransformer\n",
    "\n",
    "target = ['stlheadcount']\n",
    "\n",
    "# Creating features\n",
    "X = week_df.drop('stlheadcount', axis=1)\n",
    "\n",
    "qt_X =QuantileTransformer(output_distribution=\"normal\").fit_transform(X)\n",
    "\n",
    "# Creating target\n",
    "y = week_df['stlheadcount']\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_features = poly.fit_transform(qt_X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, random_state=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "print(predict)\n",
    "print(\"Coefficients: \\n\", model.coef_)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predict))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, predict))\n",
    "\n",
    "print(\"Train: \", model.score(X_train, y_train))\n",
    "print(\"Test: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "534c7200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2640.  3312. -8072.  2728.  2720. -1840.  2776.  1512. -4072.   616.\n",
      "   592.   432.  -504.  4200.]\n",
      "Coefficients: \n",
      " [-4.10322158e+06 -5.62639865e+06 -1.06930421e+07 -4.82291563e+06\n",
      " -3.93319942e+06  5.39714641e+16  2.69918771e+06  2.02115816e+06\n",
      "  1.47475061e+07  1.96129427e+06  5.39714641e+16  8.68674243e+06\n",
      "  2.27707100e+06 -3.98839363e+05  5.39714641e+16  5.14723896e+07\n",
      "  9.68027444e+06  5.39714643e+16 -4.65297883e+07  5.39714641e+16]\n",
      "Mean squared error: 8548808.31\n",
      "Coefficient of determination: -2.34\n",
      "Train:  0.9048721786707913\n",
      "Test:  -2.338749377254633\n"
     ]
    }
   ],
   "source": [
    "# Normalizer\n",
    "\n",
    "target = ['stlheadcount']\n",
    "\n",
    "# Creating features\n",
    "X = week_df.drop('stlheadcount', axis=1)\n",
    "\n",
    "norm_X = Normalizer().fit_transform(X)\n",
    "\n",
    "# Creating target\n",
    "y = week_df['stlheadcount']\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_features = poly.fit_transform(norm_X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, random_state=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "print(predict)\n",
    "print(\"Coefficients: \\n\", model.coef_)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predict))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, predict))\n",
    "\n",
    "print(\"Train: \", model.score(X_train, y_train))\n",
    "print(\"Test: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685bb360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3bd504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
